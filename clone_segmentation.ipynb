{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clone segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNoE+4flNCHPqnZRHEBSHTQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kyveli-tsioli/cycada_release/blob/master/clone_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weXWm25QyqUU",
        "outputId": "79139da2-2a56-44b7-dcf3-23b83b98f678"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLgg7WOMyrNp"
      },
      "source": [
        "print(os.getcwd())\n",
        "#os.chdir('/content/gdrive/My Drive')\n",
        "\n",
        "#import MUNIT as mu\n",
        "os.chdir('/content/gdrive/MyDrive/MUNIT_gta2cityscapes')\n",
        "from trainer import MUNIT_Trainer\n",
        "from utils import * #ta kanei import ola"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCf8qAxYPjVK"
      },
      "source": [
        "#read all hyperparameters from the config.yaml file\n",
        "hyperparameters= get_config('../cityscapes/gta2cityscapes_folder.yaml')\n",
        "print(hyperparameters)\n",
        "\n",
        "class Opts:\n",
        "  pass\n",
        "opts= Opts()\n",
        "opts.gpu_ids= [0]\n",
        "\n",
        "\n",
        "#create an object from MUNIT_Trainer class with the given hyperparameters \n",
        "trainer= MUNIT_Trainer(hyperparameters, opts)\n",
        "\n",
        "\n",
        "#state_dict = torch.load('../segmentation/check/gen_00150000.pt')\n",
        "#print(state_dict)\n",
        "\n",
        "#for key,value in state_dict['a'].items():\n",
        "  #print (key)\n",
        "\n",
        "#trainer.gen_a.load_state_dict(state_dict['a'])\n",
        "#trainer.gen_b.load_state_dict(state_dict['b'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWTyY0oXPjXU"
      },
      "source": [
        "#get latest checkpoints, resume stores generators, discriminators and optimizers \n",
        "trainer.resume('../segmentation/check', hyperparameters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufBAGWVZPqK_"
      },
      "source": [
        "# Import packages\n",
        "import os,sys,humanize,psutil,GPUtil\n",
        "\n",
        "# Define function\n",
        "def mem_report():\n",
        "  print(\"CPU RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ))\n",
        "  \n",
        "  GPUs = GPUtil.getGPUs()\n",
        "  for i, gpu in enumerate(GPUs):\n",
        "    print('GPU {:d} ... Mem Free: {:.0f}MB / {:.0f}MB | Utilization {:3.0f}%'.format(i, gpu.memoryFree, gpu.memoryTotal, gpu.memoryUtil*100))\n",
        "    \n",
        "# Execute function\n",
        "mem_report()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IX27YVhPqNE"
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "#import commands\n",
        "import subprocess\n",
        "#print(commands.getoutput('nvidia-smi'))\n",
        "print(subprocess.getoutput('nvidia-smi'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JsmCpyGPqPS"
      },
      "source": [
        "print(os.getcwd())\n",
        "os.chdir('/content/gdrive/MyDrive/segmentation/data')\n",
        "print(os.getcwd())\n",
        "import util"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eW3OP2urPxWs"
      },
      "source": [
        "dirpath, dirnames, filenames = next(os.walk(\"/content/gdrive/MyDrive/cityscapes\"))\n",
        "file_count = len(filenames)\n",
        "print(file_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOhV8RWNPxY4"
      },
      "source": [
        "print(os.getcwd())\n",
        "os.chdir('/content/gdrive/MyDrive/segmentation/data')\n",
        "print(os.getcwd())\n",
        "!pwd\n",
        "\n",
        "import data_loader\n",
        "#commented the 'from util import to_tensor_raw' in the data_loader.py \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCh0MTqdPxa9"
      },
      "source": [
        "os.chdir('/content/gdrive/MyDrive/segmentation')\n",
        "print(os.getcwd())\n",
        "!pwd\n",
        "\n",
        "from train_fcn import main\n",
        "#changed the 'from data.data_loader import get_fcn_dataset as get_dataset' to 'from data_loader import get_fcn_dataset as get_dataset' in the train_fcn.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF1vCTxNPjZa"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/segmentation\n",
        "%pwd\n",
        "#!ls\n",
        "\n",
        "#os.chdir('../segmentation/data')\n",
        "###os.chdir('/content/gdrive/MyDrive/segmentation')\n",
        "\n",
        "\n",
        "###\n",
        "print(os.getcwd())\n",
        "#os.chdir('/content/gdrive/My Drive')\n",
        "\n",
        "\n",
        "os.chdir('/content/gdrive/MyDrive/segmentation/data') #douleuei \n",
        "\n",
        "\n",
        "#import data_loader #douleue mazi me to allo \n",
        "\n",
        "#print(os.getcwd())\n",
        "#import data\n",
        "#print(data.__file__)\n",
        "\n",
        "\n",
        "#thelw na parw tin main apo to train_fcn.py pou diavazei to dataset\n",
        "#kai na tin tropopoiisw wste na kanw access se kathe eikona kai sto label tis \n",
        "\n",
        "#from data import data_loader\n",
        "\n",
        "#from train_fcn import main"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crz_Ns8e0tii"
      },
      "source": [
        "content_encoder_real=trainer.gen_b.enc_content #object \n",
        "print(type(content_encoder_real))\n",
        "#print(content_encoder_real) #architecture "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFBjq8Oz07Ha"
      },
      "source": [
        "loader.dataset[0][0].unsqueeze(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw9xH8KT07Jv"
      },
      "source": [
        "#sample styles\n",
        "#styles_real=trainer.s_b tha dinei to idio style code vector kathe fora\n",
        "display_size= 16 \n",
        "style_dim=8\n",
        "\n",
        "styles_real= torch.randn(display_size,style_dim, 1, 1) #tensor filled with random numbers from standard normal distr\n",
        "#style_rand = Variable(np.sqrt(10)*torch.randn(num_style, style_dim, 1, 1).cuda()) #experiment with these parameters during testing\n",
        "\n",
        "print(styles_real)\n",
        "print(len(styles_real)) #random vector\n",
        "#gia na parw diaforetika style codes:  s_b = torch.randn(display_size, self.style_dim, 1, 1).cuda()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FtVA6Fu07Lt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w04n6Tr40tk1"
      },
      "source": [
        "#print(content_encoder)\n",
        "#get decoder (generator) of real (leftlmg8bit) domain\n",
        "decoder_real=trainer.gen_b.dec  #to construct a synthetic image \n",
        "print(type(decoder_real))\n",
        "#print(decoder_real)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-N72nJC0tnC"
      },
      "source": [
        "print(\"shape of synthetic\", synthetic.shape) #torch.Size([1, 3, 512, 1024])\n",
        "    \n",
        "    synthetic_view= synthetic.view(synthetic.shape[2], synthetic.shape[3], synthetic.shape[1])\n",
        "    #print(\"synthetic view shape\", synthetic_view.shape) #torch.Size([512, 1024, 3])\n",
        "    synthetic_view_numpy= synthetic_view.cpu().detach().numpy() \n",
        "    #print(\"synthetic view numpy\", np.shape(synthetic_view_numpy)) #(512, 1024, 3)\n",
        "    \n",
        "    #synthetic image is produced by MUNIT so it has to be in the [-1,1] range\n",
        "    #print(np.min(synthetic_view_numpy)) #-0.84\n",
        "    #print(np.max(synthetic_view_numpy)) #0.999\n",
        "\n",
        "\n",
        "\n",
        "    #Floating point image RGB values must be in the 0..1 range, so:\n",
        "    synthetic_view_numpy_rgb= 0.5 * synthetic_view_numpy +0.5  #bring it to [0,1]\n",
        "\n",
        "    #print(np.min(synthetic_view_numpy_rgb)) #0.078\n",
        "    #print(np.max(synthetic_view_numpy_rgb)) #0.999\n",
        "    \n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "    plt.imsave(\"synthetic_view_numpy_rgb_1.png\",synthetic_view_numpy_rgb[:170,:340,:]) #1/9 tis sinolikis eikonas\n",
        "    plt.imsave(\"synthetic_view_numpy_rgb.png\",synthetic_view_numpy_rgb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RasC4d3pDnVf"
      },
      "source": [
        "    #loader.dataset[index]: sample a SPECIFIC image id (specifies the image), returns a tuple of 3 tensors: img1, img2 and label of this specific image\n",
        "    #loader.dataset[index][0]: 1os metasximatismos tis sigkekrimenis eikonas (img1)\n",
        "    #loader.dataset[index][1]: 2os metasximatismos tis sigkekrimenis eikonas (img2) sto [-1,1]\n",
        "    #loader.dataset[i][0]: segmentation network, for loop: i-th image, 1st transformation\n",
        "  \n",
        "    \n",
        "    #print(\"check values of loader.dataset[0][1]\",loader.dataset[500][1].unsqueeze(0))\n",
        "    #print(\"unsqueezed shape of 500th image\", loader.dataset[500][1].unsqueeze(0).shape) #Returns a new tensor with a dimension of size 1 inserted at the specified position.\n",
        "    ##torch.Size([1, 3, 512, 1024])\n",
        "    \n",
        "    #print(\"shape of 500th image\", loader.dataset[500][1].shape) #torch.Size([3, 512, 1024])\n",
        "\n",
        "    #print(\"2nd transformation (img2) in range [-1,1] of 1st image\", loader.dataset[0][1])  #epistrefei im2 (deutero metasximatismo) prwtis eikonas                         \n",
        "    #print(\"its shape\",loader.dataset[0][1].shape) #torch.Size([3, 512, 1024])\n",
        "    \n",
        "  \n",
        "    #print(\"loader dataset[0]\",loader.dataset[0]) #img1, img2  (normalised pixel intensities) and labels (each is a tensor)\n",
        "    #print(\"!!!!\",len(loader.dataset),len(loader.dataset[0]), len(loader.dataset[0][0]))\n",
        "    #print(\"loader dataset[0][0] size\", np.array(loader.dataset[0][0]).shape) #(3, 512, 1024)\n",
        "    \n",
        "    #print(\"1i eikona, 1os metasximatismos\",loader.dataset[0][0].unsqueeze(0).size()) #torch.Size([1, 3, 512, 1024])\n",
        "    #print(\"1i eikona, 1os metasximatismos\",loader.dataset[0][0].unsqueeze(0))\n",
        "\n",
        "    #print(\"loader.dataset[0][0].unsqueeze\", loader.dataset[0][0].unsqueeze(0))\n",
        "    #print(\"1i eikona, oi 2 metasximatismoi tis kai to label tis\", loader.dataset[0])\n",
        "    #print(\"loader.dataset[0][0]\",loader.dataset[0][0].size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UC3G5gq_z50"
      },
      "source": [
        "    #print(\"length of dataset\",len(dataset_)) #2975\n",
        "  \n",
        "    #exit(0) #mexri edw diavazontai oles oi eikones tou leftlmg8bit train, no error \n",
        "    #print(len(dataset[0])) #10 ???\n",
        "    #return dataset_   #stamatei kai den kanei to training "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdLvwN7q_z8T"
      },
      "source": [
        "  #synthetic image is produced by MUNIT so it has to be in the [-1,1] range\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjOh4pL9O3fi"
      },
      "source": [
        "    #dataset einai to cityscapes pou einai string\n",
        "    #loader.dataset: fortwnei ena sugkekrimeno zevgari eikonas, label\n",
        "    #ara kalw to loader gia na paei mesa sto get_item\n",
        "    #loader.dataset[0] pairnw tous 2 metasximatismous tis prwtis eikonas kai to label tis "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sMOf-Kz_z-G"
      },
      "source": [
        "    #MUNIT: to fernei sto range [-1,1] ->255 tha paei sto 1\n",
        "    #kai to 0 sto -1\n",
        "    #oi eikones pou tha dinei to cityscapes na exoun 2 normalisations\n",
        "    #me vasi tin mesi timi kai ti diaspora\n",
        "    #kai to allo na to stelnei sto [-1,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dEk2oAgypdr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QU1LYpis_0AO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}